{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# encoding: utf-8\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import math\n",
    "import pprint\n",
    "import json\n",
    "import sqlite3\n",
    "import time\n",
    "import datetime\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "#dbpath = '/Users/mszell/data/githubarchive/derived/'\n",
    "#dbname = 'githubarchive.db'\n",
    "#datapath = '/Users/mszell/data/githubarchive/raw/'\n",
    "\n",
    "dbpath = ''\n",
    "dbname = 'REPO_TEST4.sqlite'\n",
    "datapath = os.getcwd()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def date_from_filename(fname):\n",
    "    dt = datetime.datetime.strptime(fname[len('githubarchive_'):-len('.json')], '%Y-%m-%d')\n",
    "    return dt.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def date_from_json(creation_date):\n",
    "    dt = datetime.datetime.strptime(creation_date[:19], '%Y-%m-%dT%H:%M:%S')\n",
    "    return dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"Parse all data from githubarchive (daily files) to build a new sqlite db\n",
    "\n",
    "The database contains the following tables:\n",
    "repository: (repositoryid INTEGER PRIMARY KEY, repositoryname TEXT, userid TEXT, created_at INTEGER, language TEXT, description TEXT, url TEXT, fork INTEGER)\n",
    "push: (repositoryid INTEGER PRIMARY KEY, pushed_at DATE, userid TEXT)\n",
    "watch: (repositoryid INTEGER PRIMARY KEY, watched_at DATE,  userid TEXT, watchers INTEGER)\n",
    "memberadd: (repositoryid INTEGER PRIMARY KEY, added_at DATE, repositoryid INTEGER, userid INTEGER, byuserid INTEGER)\n",
    "follow: (repositoryid INTEGER PRIMARY KEY, followed_at DATE, targetuserid TEXT, followers INTEGER, repos  byuserid TEXT)\n",
    "star:()\n",
    "\n",
    "The tables contain data relevant only to those repositories which have been created in the timespan that the files cover. Exception is table follows which contains all follow events.\n",
    "\n",
    "Note: This script will only work with githubarchive data starting at 2012-09-22. Reason: Before this time, the repositoryid does not exist for PushEvents.\n",
    "\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "see below\n",
    "dbpath: string\n",
    "datapath: string\n",
    "\n",
    "Dependencies\n",
    "------------\n",
    "see imports below\n",
    "\n",
    "Returns\n",
    "-------\n",
    "n/a\n",
    "\n",
    "Example\n",
    "-------\n",
    ">>> python build_all.py\n",
    "\n",
    "See Also\n",
    "--------\n",
    "\n",
    "\n",
    "Created on  2016-10-27\n",
    "Last update 2016-10-27\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    build_repository()\n",
    "    build_push()\n",
    "    #build_watch()\n",
    "    #build_memberadd()\n",
    "    #build_follow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_create_event(event):\n",
    "    if event['payload'].get('object')=='repository' and event['repo'].get('id') and event['payload'].get('name') and event.get('actor').get('login'):\n",
    "        repo_name=event['payload'].get('name')\n",
    "        repoid=event['repo']['id']\n",
    "        created_at=date_from_json(event.get('created_at'))\n",
    "        user=event['actor']['login']\n",
    "        description='NA'\n",
    "        #print repoid, repo_name, user, created_at, description\n",
    "        return repoid, repo_name, user, created_at, description\n",
    "    elif event.get('payload') and event['payload'].get('ref_type')=='repository' and event.get('repository') and event.get('actor'):\n",
    "        repo_name=event['repository']['name']\n",
    "        repoid=event['repository']['id']\n",
    "        created_at=date_from_json(event['repository'].get('created_at'))\n",
    "        user=event['actor']\n",
    "        description=event['payload'].get('description')\n",
    "        return repoid, repo_name, user, created_at, description\n",
    "    elif event.get('payload') and event['payload'].get('ref_type')=='repository' and event.get('repo') and event.get('actor'):\n",
    "        repo_name=event['repo']['name']\n",
    "        repoid=event['repo']['id']\n",
    "        created_at=date_from_json(event.get('created_at'))\n",
    "        user=event['actor']['login']\n",
    "        description=event['payload'].get('description')\n",
    "        return repoid, repo_name, user, created_at, description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def parse(event, merging_matter):\n",
    "    #print event['type']\n",
    "    if type(event)==dict:\n",
    "        if event.get('repo') and event['repo'].get('id'):\n",
    "            if merging_matter==False:\n",
    "                d=date_from_json(event.get('created_at'))\n",
    "                if event.get('user'):\n",
    "                    if event['user']['type']=='User':\n",
    "                        u=event['user']['login']\n",
    "                        p=event['repo']['id']\n",
    "                        return (u, p, d)\n",
    "                elif event.get('actor'):\n",
    "                    if 'login' in event['actor'].keys():\n",
    "                        u=event['actor']['login']\n",
    "                        p=event['repo']['id']\n",
    "                        return (u, p, d)\n",
    "                    elif event.get('payload') and event['payload'].get('actor'):\n",
    "                        u=event['payload']['actor']\n",
    "                        p=event['repo']['id']\n",
    "                        return (u, p, d)\n",
    "            elif merging_matter==True:\n",
    "                d=date_from_json(event['payload']['pull_request']['created_at'][:10])\n",
    "                    #print d\n",
    "                if 'user' in event.keys():\n",
    "                    #print event.keys()\n",
    "                    if event['user']['type']=='User':\n",
    "                        u=event['user']['login']\n",
    "                        p=event['repo']['id']\n",
    "                        return (u, p, d)      \n",
    "                elif 'actor' in event.keys():\n",
    "                    u=event['actor']['login']\n",
    "                    p=event['repo']['id']\n",
    "                    return (u, p, d)\n",
    "        elif event.get('repository'):\n",
    "            u=event['actor']\n",
    "            p=event['repository']['id']\n",
    "            d=date_f\n",
    "            return (u, p, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_repository():\n",
    "    # Create table\n",
    "    conn = sqlite3.connect(dbpath + dbname)\n",
    "    c = conn.cursor()\n",
    "    c.execute('''DROP TABLE IF EXISTS repository''')\n",
    "    c.execute('''CREATE TABLE IF NOT EXISTS repository\n",
    "                 (repositoryid INTEGER PRIMARY KEY, repositoryname TEXT, userid TEXT, created_at DATE, description TEXT)''')\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "    # Parse files\n",
    "    #filenames = [ f for f in listdir(datapath) if isfile(join(datapath,f)) ]\n",
    "    filenames=sorted([i for i in os.listdir(datapath) if i.startswith(\"githubarchive_2011\") and i.endswith('json')])\n",
    "    for filename in filenames:\n",
    "        conn = sqlite3.connect(dbpath + dbname)\n",
    "        c = conn.cursor()\n",
    "        i = 0\n",
    "        with open(filename) as jsonfile:\n",
    "            for line in jsonfile:\n",
    "                try: \n",
    "                    jsonline = json.loads(unicode(line, errors='ignore').strip())\n",
    "                    #print jsonline.keys()\n",
    "                    if jsonline.get(\"type\") == \"CreateEvent\" and jsonline.get('payload').get('object')=='repository':\n",
    "                        try:\n",
    "                            repoid, repo_name, user, created_at, description=parse_create_event(jsonline)\n",
    "                            query = 'INSERT OR REPLACE INTO repository VALUES (?,?,?,?,?)'\n",
    "                            c.execute(query, (repoid, repo_name, user, created_at, description))\n",
    "                            i = i+1\n",
    "                            #print i\n",
    "                        except: # Rarely, JSON is not valid even if I tryy super hard\n",
    "                            pass\n",
    "                    elif jsonline.get(\"type\") == \"CreateEvent\" and jsonline.get('payload').get('ref_type')=='repository':\n",
    "                        repoid, repo_name, user, created_at, description=parse_create_event(jsonline)\n",
    "                        query = 'INSERT OR REPLACE INTO repository VALUES (?,?,?,?,?)'\n",
    "                        c.execute(query, (repoid, repo_name, user, created_at, description))\n",
    "                        i = i+1\n",
    "                except:\n",
    "                    for k in ['{\"repo\"'+l for l in line.split('{\"repo\"')[1:]]:\n",
    "                        jsonline=json.loads(unicode(k, errors='ignore').strip())\n",
    "                        last_event=jsonline\n",
    "                        if jsonline.get(\"type\") == \"CreateEvent\" and jsonline.get('payload').get('object')=='repository':\n",
    "                            try:\n",
    "                                repoid, repo_name, user, created_at, description=parse_create_event(jsonline)\n",
    "                                query = 'INSERT OR REPLACE INTO repository VALUES (?,?,?,?,?)'\n",
    "                                c.execute(query, (repoid, repo_name, user, created_at, description))\n",
    "                                i = i+1\n",
    "                            except:\n",
    "                                pass\n",
    "                        elif jsonline.get(\"type\") == \"CreateEvent\" and jsonline['payload'].get('ref_type')=='repository':\n",
    "                            repoid, repo_name, user, created_at, description=parse_create_event(jsonline)\n",
    "                            query = 'INSERT OR REPLACE INTO repository VALUES (?,?,?,?,?)'\n",
    "                            c.execute(query, (repoid, repo_name, user, created_at, description))\n",
    "                            i = i+1\n",
    "            print \"Done file \" + filename + \". Found and inserted \" + str(i) + \" valid CreationEvents.\"\n",
    "        conn.commit()\n",
    "        conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_push():\n",
    "    # Create table\n",
    "    conn = sqlite3.connect(dbpath + dbname)\n",
    "    c = conn.cursor()\n",
    "    c.execute('''DROP TABLE IF EXISTS push''')\n",
    "    c.execute('''CREATE TABLE IF NOT EXISTS push\n",
    "                 (repositoryid INTEGER PRIMARY KEY, pushed_at DATE, userlogin TEXT)''')\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "    \n",
    "    # Parse files\n",
    "    #filenames = [ f for f in listdir(datapath) if isfile(join(datapath,f)) ]\n",
    "    filenames=sorted([i for i in os.listdir(datapath) if i.startswith(\"githubarchive_2011\") and i.endswith('json')])\n",
    "    for filename in filenames:\n",
    "        conn = sqlite3.connect(dbpath + dbname)\n",
    "        c = conn.cursor()\n",
    "        i = 0\n",
    "        with open(filename) as jsonfile:\n",
    "            for line in jsonfile:\n",
    "                try: \n",
    "                    jsonline = json.loads(unicode(line, errors='ignore').strip())\n",
    "                    #print jsonline.keys()\n",
    "                    if jsonline.get(\"type\") == \"PushEvent\":\n",
    "                        try:\n",
    "                            user, project, date=parse(jsonline, False)\n",
    "                            query = 'INSERT OR REPLACE INTO push VALUES (?,?,?)'\n",
    "                            c.execute(query, (project, date, user))\n",
    "                            i = i+1\n",
    "                        except: #repoid or user id missing\n",
    "                            pass\n",
    "                except:\n",
    "                    for k in ['{\"repo\"'+l for l in line.split('{\"repo\"')[1:]]:\n",
    "                        jsonline=json.loads(unicode(k, errors='ignore').strip())\n",
    "                        last_event=jsonline\n",
    "                        if jsonline.get(\"type\") == \"PushEvent\":\n",
    "                            try:\n",
    "                                user, project, date=parse(jsonline, False)\n",
    "                                query = 'INSERT OR REPLACE INTO push VALUES (?,?,?)'\n",
    "                                c.execute(query, (project, date, user))\n",
    "                                i = i+1\n",
    "                            except: #repoid or user id missing\n",
    "                                pass\n",
    "        print \"Done file \" + filename + \". Found and inserted \" + str(i) + \" valid PushEvents.\"\n",
    "        conn.commit()\n",
    "        conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done file githubarchive_2011-02-12.json. Found and inserted 1204 valid CreationEvents.\n",
      "Done file githubarchive_2011-02-13.json. Found and inserted 1346 valid CreationEvents.\n",
      "Done file githubarchive_2011-02-14.json. Found and inserted 1565 valid CreationEvents.\n",
      "Done file githubarchive_2011-03-14.json. Found and inserted 1656 valid CreationEvents.\n",
      "Done file githubarchive_2011-03-15.json. Found and inserted 1639 valid CreationEvents.\n",
      "Done file githubarchive_2011-03-28.json. Found and inserted 1799 valid CreationEvents.\n",
      "Done file githubarchive_2011-03-30.json. Found and inserted 1833 valid CreationEvents.\n",
      "Done file githubarchive_2011-04-06.json. Found and inserted 1857 valid CreationEvents.\n",
      "Done file githubarchive_2011-04-08.json. Found and inserted 1766 valid CreationEvents.\n",
      "Done file githubarchive_2011-02-12.json. Found and inserted 15378 valid PushEvents.\n",
      "Done file githubarchive_2011-02-13.json. Found and inserted 16889 valid PushEvents.\n",
      "Done file githubarchive_2011-02-14.json. Found and inserted 20889 valid PushEvents.\n",
      "Done file githubarchive_2011-03-14.json. Found and inserted 23199 valid PushEvents.\n",
      "Done file githubarchive_2011-03-15.json. Found and inserted 23661 valid PushEvents.\n",
      "Done file githubarchive_2011-03-28.json. Found and inserted 24185 valid PushEvents.\n",
      "Done file githubarchive_2011-03-30.json. Found and inserted 25041 valid PushEvents.\n",
      "Done file githubarchive_2011-04-06.json. Found and inserted 25853 valid PushEvents.\n",
      "Done file githubarchive_2011-04-08.json. Found and inserted 23820 valid PushEvents.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TEST PARSER\n",
    "with open('githubarchive_2011-03-14.json') as jsonfile:\n",
    "    for line in jsonfile:\n",
    "        jsonline = json.loads(unicode(line, errors='ignore').strip())\n",
    "        if jsonline.get(\"type\") == \"PushEvent\":\n",
    "            user, project, date=parse(jsonline , False)\n",
    "            print user, project, date"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
