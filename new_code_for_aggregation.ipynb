{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "import json\n",
    "import os\n",
    "from collections import defaultdict\n",
    "#from emailtome import noticeEMail\n",
    "import emailtome\n",
    "import datetime\n",
    "import sys\n",
    "reload(sys)\n",
    "sys.setdefaultencoding(\"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class SetEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, set):\n",
    "            return list(obj)\n",
    "        return json.JSONEncoder.default(self, obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_user_data(event): #newest bio available from pushes, containning username,avatar url, gravatar_id, e-mail adress and real name\n",
    "    user_data=defaultdict(dict)\n",
    "    if 'payload' in event.keys():\n",
    "        if 'shas' in event['payload'].keys() and len(event['payload']['shas']):\n",
    "            if len(event['payload']['shas'][0])>=1:\n",
    "                name=event['payload']['shas'][0][-1]\n",
    "                e_mail=event['payload']['shas'][0][1]\n",
    "        else:\n",
    "            name='Nan'\n",
    "            e_mail='Nan' \n",
    "    else:\n",
    "            name='Nan'\n",
    "            e_mail='Nan' \n",
    "\n",
    "    if 'actor' in event.keys(): \n",
    "        if 'id' in event['actor'].keys():\n",
    "            user_data[event['actor']['id']]={'username':event['actor']['login'], \n",
    "                                         'avatar_url': event['actor']['avatar_url'],\n",
    "                                         'gravatar_id': event['actor']['gravatar_id'],\n",
    "                                         'e-mail_adress': e_mail,\n",
    "                                         'name':name}\n",
    "    return user_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def write(p, file_name, dataset):\n",
    "        with open(p+file_name+\".json\",\"w\") as f:\n",
    "            json.dump(dataset,f, cls=SetEncoder)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_aggr_file(p, directory, filename, id_repo): #aggregate the data and generates user based json files\n",
    "    errors=[]\n",
    "    with open(os.path.join(directory,filename), 'r') as myfile:\n",
    "        data=myfile.read()\n",
    "    #print 'opened the file'\n",
    "    lines=data.splitlines()\n",
    "    for i in range(0, len(lines)):\n",
    "        try:\n",
    "            event=json.loads(lines[i].encode('utf-8').strip())\n",
    "            if 'repo' in event.keys():\n",
    "                if 'id' in event['repo'].keys() and 'id' in event['actor'].keys():\n",
    "                    id_repo[event['actor']['id']].add(event['repo'][u'id'])\n",
    "                    user_id=event['actor']['id']\n",
    "                    user_data.update(get_user_data(event))\n",
    "        except ValueError as e:\n",
    "            error=((str(filename)+','+str(e)+','+str(lines[i])+'\\n'))\n",
    "            with open(p+filename+\"_errors.txt\",\"a\") as f:\n",
    "                f.write(error)\n",
    "    return id_repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2011-02.json                      githubarchive_2011-02-12.json\r\n",
      "2011-03.json                      githubarchive_2011-02-13.json\r\n",
      "2011-03users.json                 githubarchive_2011-02-14.json\r\n",
      "2011-04.json                      githubarchive_2011-03-14.json\r\n",
      "2011-04users.json                 githubarchive_2011-03-15.json\r\n",
      "718497.txt                        githubarchive_2011-03-28.json\r\n",
      "718505.txt                        githubarchive_2011-03-30.json\r\n",
      "718510.txt                        githubarchive_2011-04-06.json\r\n",
      "718512.txt                        githubarchive_2011-04-08.json\r\n",
      "718513.txt                        githubarchivedownloader.py\r\n",
      "718524.txt                        hst.txt\r\n",
      "718534.txt                        new_code_for_aggregation.ipynb\r\n",
      "Analyse_users.ipynb               new_code_for_aggregation.py\r\n",
      "all_user_attributes.json          test.py\r\n",
      "database_creation.ipynb           test.txt\r\n",
      "database_creation.py              \u001b[31mtest2.py\u001b[m\u001b[m*\r\n",
      "date_id_repos.json                test_new_code_for_aggregation.py\r\n",
      "\u001b[34mdiversity-master\u001b[m\u001b[m/                 user_data.json\r\n",
      "emailtome.py                      userid.txt\r\n",
      "emailtome.pyc\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_data=defaultdict(dict)\n",
    "id_repo=defaultdict(set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a=read_aggr_file('','', 'githubarchive_2011-03-15.json', id_repo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cat githubarchive_2011-03-15.json_errors.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"def get_activity(lines, aggr): #list of repositories pushed code by users by days\n",
    "    id_repo=defaultdict(dict)\n",
    "\n",
    "    for i in range(0, len(lines)):\n",
    "        event=json.loads(lines[i].encode('utf-8').strip())\n",
    "        #print event['type']\n",
    "        if 'repo' in event.keys():\n",
    "            if 'id' in event['repo'].keys() and 'id' in event['actor'].keys():\n",
    "                id_repo[event['actor']['id']].add(event['repo'][u'id'])\n",
    "    return id_repo\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['githubarchive_2011-02-12.json',\n",
       " 'githubarchive_2011-02-14.json',\n",
       " 'githubarchive_2011-03-30.json']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "sorted([i for i in os.listdir(os.getcwd()) if i.endswith(\".json\") and i.startswith(\"githubarchive\")])[:5:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2011-02-12 2011-02-12 before openning the file\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "read_aggr_file() takes exactly 4 arguments (3 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-7739d9c2ee5b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maggr\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'month'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdate_s\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mold_date_s\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0mid_repo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mread_aggr_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid_repo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m             \u001b[0mold_date_s\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdate_s\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mnumber_of_elements\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: read_aggr_file() takes exactly 4 arguments (3 given)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "import json\n",
    "directory=os.getcwd()\n",
    "#old_date_s=os.listdir(os.getcwd())[0]\n",
    "old_date_s='2011-02-12'\n",
    "#path=\"/mnt/cns_storage/home/vorsi/derived_new\"\n",
    "#directory= '/mnt/cns_storage/home/github_shared/data/raw'\n",
    "path=''\n",
    "aggr='month'\n",
    "\n",
    "id_repo=defaultdict(set)\n",
    "user_data=defaultdict(dict)\n",
    "count=0\n",
    "files=sorted([i for i in os.listdir(directory) if i.endswith(\".json\") and i.startswith(\"githubarchive\")])\n",
    "number_of_elements=len(files)\n",
    "\n",
    "for filename in files:\n",
    "    count+=1\n",
    "    date_s=filename.split('_')[1][:-len('.json')]\n",
    "    print date_s, old_date_s, 'before openning the file'\n",
    "    if aggr=='month':\n",
    "        if date_s[:7]==old_date_s[:7]:\n",
    "            id_repo=read_aggr_file(directory, filename, id_repo)\n",
    "            old_date_s=date_s\n",
    "            if count==number_of_elements:\n",
    "                write(path, date_s[:7], id_repo)\n",
    "                write(path, date_s[:7]+'users', user_data)\n",
    "        else:\n",
    "            if count==number_of_elements:\n",
    "                print count\n",
    "                write(path, date_s[:7], id_repo)\n",
    "                write(path, date_s[:7]+'users', user_data)\n",
    "            else:\n",
    "                write(path, old_date_s[:7], id_repo)\n",
    "                write(path, date_s[:7]+'users', user_data)\n",
    "                id_repo=defaultdict(set)\n",
    "                user_data=defaultdict(dict)\n",
    "                id_repo=read_aggr_file(directory, filename, id_repo)\n",
    "                old_date_s=date_s\n",
    "                    \n",
    "    if aggr=='year':\n",
    "        if date_s[:4]==old_date_s[:4]:\n",
    "            id_repo=read_aggr_file(directory, filename, id_repo)\n",
    "            old_date_s=date_s\n",
    "            if count==number_of_elements:\n",
    "                write(path, date_s[:4], id_repo)\n",
    "                write(path, date_s[:4]+'users', user_data)\n",
    "        else:\n",
    "            if count==number_of_elements:\n",
    "                write(path, date_s[:4], id_repo)\n",
    "                write(path, date_s[:4]+'users', user_data)\n",
    "            else:\n",
    "                write(path, old_date_s[:4], id_repo)\n",
    "                write(path, date_s[:4]+'users', user_data)\n",
    "                id_repo=defaultdict(set)\n",
    "                id_repo=read_aggr_file(directory, filename, id_repo)\n",
    "                old_date_s=date_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "starttime=datetime.datetime.now()\n",
    "usr='orsolya.vasarhelyi'\n",
    "psw='Vlak201188'\n",
    "fromaddr='orsolya.vasarhelyi@gmail.com'\n",
    "toaddr='orsolya.vasarhelyi@gmail.com'\n",
    "emailtome.noticeEMail(starttime, usr, psw, fromaddr, toaddr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user_attributes={}\n",
    "for filename in os.listdir(path):\n",
    "    if filename.endswith(\"users.json\"):\n",
    "        with open(filename) as data_file:    \n",
    "            data = json.load(data_file)\n",
    "            user_attributes.update(data)\n",
    "write(path, 'all_user_attributes', user_attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "starttime=datetime.datetime.now()\n",
    "usr='orsolya.vasarhelyi'\n",
    "psw='Vlak201188'\n",
    "fromaddr='orsolya.vasarhelyi@gmail.com'\n",
    "toaddr='orsolya.vasarhelyi@gmail.com'\n",
    "emailtome.noticeEMail(starttime, usr, psw, fromaddr, toaddr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#sorted(os.listdir(os.getcwd()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
