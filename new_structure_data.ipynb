{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import defaultdict, Counter\n",
    "from emailtome import noticeEMail\n",
    "import urllib, json, csv\n",
    "import emailtome\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "starttime=datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"def read_aggr_file(p, directory, filename, et): #aggregate the data and generates user based json files\\n    pres=[]\\n    with open(os.path.join(directory,filename), 'r') as myfile:\\n        data=myfile.read()\\n    #print 'opened the file'\\n    lines=data.splitlines()\\n    for i in range(0, 1000):\\n        event=json.loads(lines[i].strip())\\n        #print event.keys()\\n        #types.add(event['type'])\\n        if event['type']==et:\\n            PRE=event\\n            return PRE\""
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"def read_aggr_file(p, directory, filename, et): #aggregate the data and generates user based json files\n",
    "    pres=[]\n",
    "    with open(os.path.join(directory,filename), 'r') as myfile:\n",
    "        data=myfile.read()\n",
    "    #print 'opened the file'\n",
    "    lines=data.splitlines()\n",
    "    for i in range(0, 1000):\n",
    "        event=json.loads(lines[i].strip())\n",
    "        #print event.keys()\n",
    "        #types.add(event['type'])\n",
    "        if event['type']==et:\n",
    "            PRE=event\n",
    "            return PRE\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def date_from_filename(fname):\n",
    "    dt = datetime.datetime.strptime(fname[len('githubarchive_'):-len('.json')], '%Y-%m-%d')\n",
    "    return dt.strftime('%Y-%m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def date_from_json(creation_date):\n",
    "    dt = datetime.datetime.strptime(creation_date[:10], '%Y-%m-%d')\n",
    "    return dt.strftime('%Y-%m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def url_to_json(link):\n",
    "    url = link\n",
    "    response = urllib.urlopen(url)\n",
    "    data = json.loads(response.read())\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def parse(event, date_f, merging_matter):\n",
    "    #print event['type']\n",
    "    if type(event)==dict:\n",
    "        if 'repo' in event.keys(): \n",
    "            #print'k'\n",
    "            if 'id' in event['repo'].keys():\n",
    "                #print 'id in repo'\n",
    "                if merging_matter==False:\n",
    "                    d=date_f\n",
    "                    if 'user' in event.keys():\n",
    "                        if event['user']['type']=='User':\n",
    "                            u=event['user']['login']\n",
    "                            p=event['repo']['id']\n",
    "                            return (u, p, d)\n",
    "                    elif 'actor' in event.keys():\n",
    "                        if 'login' in event['actor'].keys():\n",
    "                            u=event['actor']['login']\n",
    "                            p=event['repo']['id']\n",
    "                            return (u, p, d)\n",
    "                        elif 'payload' in event.keys():\n",
    "                            if 'actor' in event['payload'].keys():\n",
    "                                u=event['payload']['actor']\n",
    "                                p=event['repo']['id']\n",
    "                                return (u, p, d)\n",
    "                elif merging_matter==True:\n",
    "                    d=date_from_json(event['payload']['pull_request']['created_at'][:10])\n",
    "                    #print d\n",
    "                    if 'user' in event.keys():\n",
    "                        #print event.keys()\n",
    "                        if event['user']['type']=='User':\n",
    "                            u=event['user']['login']\n",
    "                            p=event['repo']['id']\n",
    "                            return (u, p, d)      \n",
    "                    elif 'actor' in event.keys():\n",
    "                        u=event['actor']['login']\n",
    "                        p=event['repo']['id']\n",
    "                        return (u, p, d)\n",
    "            else:\n",
    "                return ('error' ,_,_)\n",
    "        elif 'repository' in event.keys():\n",
    "            u=event['actor']\n",
    "            p=event['repository']['id']\n",
    "            d=date_f\n",
    "            return (u, p, d)\n",
    "        else:\n",
    "            return ('error' ,_,_)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#returns user, project, date, number of commits pushed\n",
    "def parse_number_of_pushed_commits(event, date_f):\n",
    "    u,p,d=parse_push(event, date_f)\n",
    "    c=len(event['payload']['commits'])\n",
    "    return(u,p,d,c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def parse_follow_event(event):\n",
    "    if type(event['actor'])==dict:\n",
    "        f=event['payload']['actor']\n",
    "        t=event['payload']['target']['login']\n",
    "    else:\n",
    "        f=event['actor']\n",
    "        t=event['payload']['target']['login']\n",
    "    return (f,t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_membership_event(event):\n",
    "    u=event['actor']['login']\n",
    "    o=event['org']['login']\n",
    "    a=event['payload']['action']\n",
    "    return (u,o,a) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def parse_member_event(event):\n",
    "    if 'repo' not in event.keys():\n",
    "        u=event['actor']\n",
    "        r=event['repository']['name']\n",
    "        o=event['repository']['owner']\n",
    "        a=event['payload']['action']\n",
    "        return (u,r,o,a) \n",
    "    elif type(event['payload']['member'])==dict:\n",
    "        u=event['payload']['member']['login']\n",
    "        r=event['repo']['name']\n",
    "        o=event['actor']['login']\n",
    "        a=event['payload']['action']\n",
    "    else:\n",
    "        u=event['payload']['member']\n",
    "        r=event['repo']['name']\n",
    "        o=event['payload']['actor']\n",
    "        a=event['payload']['action']\n",
    "        return (u,r,o,a)         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_projects_dict(all_projects, user, project, date, eventt):\n",
    "    if project not in all_projects.keys():\n",
    "        events=defaultdict(dict)\n",
    "        users=defaultdict(dict)\n",
    "        dates=defaultdict(dict)\n",
    "        dates[date]=1\n",
    "        users[user]=dates\n",
    "        events[eventt]=users\n",
    "        all_projects[project]=events\n",
    "        return all_projects\n",
    "    elif eventt not in all_projects[project].keys():\n",
    "        users=defaultdict(dict)\n",
    "        dates=defaultdict(dict)\n",
    "        dates[date]=1\n",
    "        users[user]=dates\n",
    "        all_projects[project][eventt]=users\n",
    "        return all_projects \n",
    "    elif user not in all_projects[project][eventt].keys():\n",
    "        dates=defaultdict(dict)\n",
    "        dates[date]=1\n",
    "        all_projects[project][eventt][user]=dates\n",
    "        #print projects[project].keys()\n",
    "        return all_projects\n",
    "    elif date not in all_projects[project][eventt][user].keys():\n",
    "        dates=defaultdict(dict)\n",
    "        dates[date]=1\n",
    "        all_projects[project][eventt][user]=dates\n",
    "        return all_projects\n",
    "    else:\n",
    "        all_projects[project][eventt][user][date]+=1\n",
    "        return all_projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_user_activity(user_activity, user, project, date, eventt):\n",
    "    if user not in user_activity.keys():\n",
    "        projects=defaultdict(dict)\n",
    "        events=defaultdict(dict)\n",
    "        dates=defaultdict(dict)\n",
    "        dates[date]=1\n",
    "        events[eventt]=dates\n",
    "        projects[project]=events\n",
    "        user_activity[user]=projects\n",
    "        return user_activity\n",
    "    elif project not in user_activity[user].keys():\n",
    "        projects=defaultdict(dict)\n",
    "        events=defaultdict(dict)\n",
    "        dates=defaultdict(dict)\n",
    "        dates[date]=1\n",
    "        events[eventt]=dates\n",
    "        projects[project]=events\n",
    "        user_activity[user][project]=events\n",
    "        return user_activity \n",
    "    elif eventt not in user_activity[user][project].keys():\n",
    "        dates=defaultdict(dict)\n",
    "        events=defaultdict(dict)\n",
    "        dates[date]=1\n",
    "        events[eventt]=dates\n",
    "        user_activity[user][project][eventt]=dates\n",
    "        return user_activity\n",
    "    elif date not in user_activity[user][project][eventt].keys():\n",
    "        dates=defaultdict(dict)\n",
    "        dates[date]=1\n",
    "        user_activity[user][project][eventt]=dates\n",
    "        return user_activity\n",
    "    else:\n",
    "        user_activity[user][project][eventt][date]+=1\n",
    "        return user_activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"all_projects=defaultdict(dict)\\np_u=((1,30, datetime.date(2015, 12, 29), 'pd'), (2,30, datetime.date(2015, 12, 30), 'pd'), (1,20, datetime.date(2015, 12, 29), 'ab'), (1,20, datetime.date(2015, 12, 29), 'ab'))\\nfor (u, p, d, e) in p_u:\\n    h=get_projects_dict(all_projects, u, p, d, e)\""
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TEST\n",
    "\"\"\"all_projects=defaultdict(dict)\n",
    "p_u=((1,30, datetime.date(2015, 12, 29), 'pd'), (2,30, datetime.date(2015, 12, 30), 'pd'), (1,20, datetime.date(2015, 12, 29), 'ab'), (1,20, datetime.date(2015, 12, 29), 'ab'))\n",
    "for (u, p, d, e) in p_u:\n",
    "    h=get_projects_dict(all_projects, u, p, d, e)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def all_event_parser(event, date_file, follow_follower_network, all_projects, memberships, repo_memberships, users, user_activity):\n",
    "    et=event['type']\n",
    "    if et=='FollowEvent':\n",
    "        f,t=parse_follow_event(event)\n",
    "        follow_follower_network.append((f,t,date_file))\n",
    "        users.add(f)\n",
    "        users.add(t)\n",
    "    elif et=='MembershipEvent':\n",
    "        u,o,a=parse_membership_event(event)\n",
    "        memberships.append((u,o,a, date_file))\n",
    "        users.add(u)\n",
    "    elif et=='MemberEvent':\n",
    "        u,r,o,a=parse_member_event(event)\n",
    "        repo_memberships.append((u,r,o,a,date_file))\n",
    "        users.add(u)\n",
    "        users.add(o)\n",
    "    elif et=='PullRequestEvent' and event['payload']['action']=='closed':\n",
    "        if 'merged' in event ['payload']['pull_request']:\n",
    "            if event['payload']['pull_request']['merged']==True:\n",
    "                user, project, date=parse(event, date_file, True)\n",
    "                all_projects=get_projects_dict(all_projects, user, project, date, u'Closed_PullRequestEvent')\n",
    "                user_activitiy=get_user_activity(user_activity, user, project, date, et)\n",
    "                #return all_projects, follow_follower_network, memberships, repo_memberships, users\n",
    "    elif et not in ['GistEvent','GollumEvent','CreateEvent','DeleteEvent','MemberEvent']:\n",
    "        user, project, date=parse(event, date_file, False)\n",
    "        if user!='error':\n",
    "            all_projects=get_projects_dict(all_projects, user, project, date, et)\n",
    "            user_activity=get_user_activity(user_activity, user, project, date, et)\n",
    "    return all_projects, follow_follower_network, memberships, repo_memberships, users,user_activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SetEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, set):\n",
    "            return list(obj)\n",
    "        return json.JSONEncoder.default(self, obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_json(p, d, file_name, data):\n",
    "        with open(p+str(d)+file_name+\".json\",\"w\") as f:\n",
    "            json.dump(data,f, cls=SetEncoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def write_csv(p, d, file_name, data):\n",
    "    with open(p+str(d)+file_name+\".csv\",\"w\") as csvfile:\n",
    "        a=csv.writer(csvfile, delimiter=',')\n",
    "        a.writerows(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_users(p, d, file_name, data):\n",
    "    with open(p+str(d)+file_name+\".csv\",\"w\") as u:\n",
    "        u.write( '\\n'.join(users) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def write_all(path, date_file, all_projects, follow_follower_network, memberships, repo_memberships, user_activity, users):         \n",
    "    write_json(path, date_file, '_all_projects', all_projects)\n",
    "    write_csv(path, date_file, '_follow_follower_network', follow_follower_network)\n",
    "    write_csv(path, date_file, '_memberships', memberships)\n",
    "    write_csv(path, date_file, '_repo_memberships', repo_memberships)\n",
    "    write_json(path, date_file, '_user_activity', user_activity)\n",
    "    write_users(path, date_file, '_users', users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_lines(data, follow_follower_network, all_projects, memberships, repo_memberships, users, user_activity):\n",
    "    lines=data.splitlines()\n",
    "    for i in range(0,len(lines)):\n",
    "        last_line=lines[i]\n",
    "        try:\n",
    "            event=json.loads(unicode(lines[i], errors='ignore').strip())\n",
    "            last_event=event\n",
    "            all_projects,follow_follower_network, memberships, repo_memberships,users, user_activity=all_event_parser(event, date_file, follow_follower_network, all_projects, memberships, repo_memberships, users, user_activity)\n",
    "        except ValueError:\n",
    "            for k in ['{\"repo\"'+line for line in lines[i].split('{\"repo\"')[1:]]:\n",
    "                event=json.loads(k)\n",
    "                all_projects,follow_follower_network, memberships, repo_memberships, users, user_activity=all_event_parser(event, date_file, follow_follower_network, all_projects, memberships, repo_memberships, users, user_activity)\n",
    "    return all_projects,follow_follower_network, memberships, repo_memberships, users, user_activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path=''\n",
    "directory=''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'projects={project_id: user_id{pull_requests_merged: {date: count},\\n                        pull_requests_non_merged: {date: count},\\n                        pushes: {date: count},\\n                        forks: {date: count},\\n                        watches: {date: count},\\n                        \\nuser_activity={user_id: project_id{pull_requests_merged: {date: count},\\n                        pull_requests_non_merged: {date: count},\\n                        pushes: {date: count},\\n                        forks: {date: count},\\n                        watches: {date: count},\\n                        stars: {date: count}'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"projects={project_id: user_id{pull_requests_merged: {date: count},\n",
    "                        pull_requests_non_merged: {date: count},\n",
    "                        pushes: {date: count},\n",
    "                        forks: {date: count},\n",
    "                        watches: {date: count},\n",
    "                        \n",
    "user_activity={user_id: project_id{pull_requests_merged: {date: count},\n",
    "                        pull_requests_non_merged: {date: count},\n",
    "                        pushes: {date: count},\n",
    "                        forks: {date: count},\n",
    "                        watches: {date: count},\n",
    "                        stars: {date: count}\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_projects=defaultdict(dict)\n",
    "user_activity=defaultdict(dict)\n",
    "follow_follower_network=[]\n",
    "memberships=[]\n",
    "repo_memberships=[]\n",
    "users=set()\n",
    "directory=''\n",
    "path=os.getcwd()\n",
    "count=0\n",
    "files=sorted([i for i in os.listdir(path) if i.startswith(\"githubarchive\") and i.endswith('json')])\n",
    "number_of_elements=len(files)\n",
    "old_date=date_from_filename(files[0])\n",
    "for f in files:\n",
    "    print f\n",
    "    count+=1\n",
    "    with open(os.path.join(path,f), 'r') as myfile:\n",
    "        data=myfile.read()\n",
    "        date_file=date_from_filename(f)\n",
    "        if date_file==old_date:\n",
    "            print date_file, old_date\n",
    "            old_date=date_file\n",
    "            all_projects,follow_follower_network, memberships, repo_memberships, users, user_activity=read_lines(data, follow_follower_network, all_projects, memberships, repo_memberships, users, user_activity)\n",
    "            if count==number_of_elements:\n",
    "                print date_file, old_date, count, number_of_elements\n",
    "                write_all(directory, date_file, all_projects, follow_follower_network, memberships, repo_memberships, user_activity, users)\n",
    "        else:\n",
    "            if count==number_of_elements:\n",
    "                print date_file, old_date, count, number_of_elements\n",
    "                write_all(directory, date_file, all_projects, follow_follower_network, memberships, repo_memberships, user_activity, users)\n",
    "            else:\n",
    "                print date_file, old_date, count, number_of_elements\n",
    "                write_all(directory, date_file, all_projects, follow_follower_network, memberships, repo_memberships, user_activity, users)\n",
    "                all_projects=defaultdict(dict)\n",
    "                user_activity=defaultdict(dict)\n",
    "                follow_follower_network=[]\n",
    "                memberships=[]\n",
    "                repo_memberships=[]\n",
    "                users=set()\n",
    "                all_projects,follow_follower_network, memberships, repo_memberships, users, user_activity=read_lines(data, follow_follower_network, all_projects, memberships, repo_memberships, users, user_activity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "usr=''\n",
    "psw=''\n",
    "fromaddr=''\n",
    "toaddr=''\n",
    "emailtome.noticeEMail(starttime, usr, psw, fromaddr, toaddr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
